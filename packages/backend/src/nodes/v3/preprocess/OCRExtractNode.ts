/**
 * OCR Extract Node - OCRæ–‡æœ¬æå–èŠ‚ç‚¹
 * 
 * åŠŸèƒ½ï¼š
 * - ç»Ÿä¸€OCRæœåŠ¡æ¥å£
 * - å¤šäº‘æœåŠ¡æ”¯æŒï¼ˆé˜¿é‡Œäº‘ã€ç™¾åº¦ã€è…¾è®¯äº‘ï¼‰
 * - æ‰¹é‡å›¾ç‰‡å¤„ç†
 * - ç»“æœç¼“å­˜
 * - ç½®ä¿¡åº¦è¿‡æ»¤
 * 
 * å¤æ‚åº¦ï¼šMï¼ˆä¸­ï¼‰
 */

import { BaseNodeV3, NodeManifest, NodeExecutionResult, NodeExecutionContext } from '../BaseNode';
import type { Records, AuditDataType } from '../../../types/AuditDataTypes';

interface OCRConfig {
  provider?: 'aliyun' | 'baidu' | 'tencent' | 'azure' | 'google';
  language?: 'zh' | 'en' | 'auto';
  minConfidence?: number;      // æœ€å°ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
  enableCache?: boolean;       // å¯ç”¨ç¼“å­˜
  batchSize?: number;          // æ‰¹å¤„ç†å¤§å°
  timeout?: number;            // è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
}

interface OCRResult {
  text: string;
  confidence: number;
  lines: Array<{
    text: string;
    confidence: number;
    boundingBox?: number[];
  }>;
  words: Array<{
    text: string;
    confidence: number;
  }>;
}

export class OCRExtractNode extends BaseNodeV3 {
  getManifest(): NodeManifest {
    return {
      type: 'preprocess.ocr_extract',
      version: '1.0.0',
      category: 'preprocess',
      
      label: {
        zh: 'OCRæ–‡æœ¬æå–',
        en: 'OCR Text Extract'
      },
      
      description: {
        zh: 'ä»å›¾ç‰‡ä¸­æå–æ–‡æœ¬ã€‚æ”¯æŒå¤šä¸ªOCRæœåŠ¡æä¾›å•†ï¼ˆé˜¿é‡Œäº‘ã€ç™¾åº¦ã€è…¾è®¯äº‘ç­‰ï¼‰ï¼Œæ‰¹é‡å¤„ç†ï¼Œç»“æœç¼“å­˜ï¼Œç½®ä¿¡åº¦è¿‡æ»¤ã€‚',
        en: 'Extract text from images. Support multiple OCR providers (Aliyun, Baidu, Tencent, etc.), batch processing, result caching, confidence filtering.'
      },
      
      icon: 'ğŸ”',
      color: '#3498DB',
      
      inputs: [
        {
          id: 'images',
          name: 'images',
          type: 'Records',
          required: true,
          description: {
            zh: 'åŒ…å«å›¾ç‰‡è·¯å¾„çš„è®°å½•',
            en: 'Records with image paths'
          }
        }
      ],
      
      outputs: [
        {
          id: 'texts',
          name: 'texts',
          type: 'Records',
          required: true,
          description: {
            zh: 'æå–çš„æ–‡æœ¬è®°å½•',
            en: 'Extracted text records'
          }
        },
        {
          id: 'metadata',
          name: 'metadata',
          type: 'Records',
          required: true,
          description: {
            zh: 'OCRå…ƒæ•°æ®ï¼ˆç½®ä¿¡åº¦ã€è¡Œæ•°ç­‰ï¼‰',
            en: 'OCR metadata (confidence, line count, etc.)'
          }
        }
      ],
      
      config: [
        {
          id: 'provider',
          name: { zh: 'OCRæœåŠ¡å•†', en: 'OCR Provider' },
          type: 'select',
          required: false,
          defaultValue: 'aliyun',
          options: [
            { label: 'é˜¿é‡Œäº‘ OCR', value: 'aliyun' },
            { label: 'ç™¾åº¦ OCR', value: 'baidu' },
            { label: 'è…¾è®¯äº‘ OCR', value: 'tencent' },
            { label: 'Azure Computer Vision', value: 'azure' },
            { label: 'Google Cloud Vision', value: 'google' }
          ]
        },
        {
          id: 'language',
          name: { zh: 'è¯­è¨€', en: 'Language' },
          type: 'select',
          required: false,
          defaultValue: 'auto',
          options: [
            { label: 'è‡ªåŠ¨æ£€æµ‹', value: 'auto' },
            { label: 'ä¸­æ–‡', value: 'zh' },
            { label: 'English', value: 'en' }
          ]
        },
        {
          id: 'minConfidence',
          name: { zh: 'æœ€å°ç½®ä¿¡åº¦', en: 'Min Confidence' },
          type: 'number',
          required: false,
          defaultValue: 0.5,
          description: {
            zh: 'è¿‡æ»¤ç½®ä¿¡åº¦ä½äºæ­¤å€¼çš„ç»“æœï¼ˆ0-1ï¼‰',
            en: 'Filter results with confidence below this value (0-1)'
          }
        },
        {
          id: 'enableCache',
          name: { zh: 'å¯ç”¨ç¼“å­˜', en: 'Enable Cache' },
          type: 'boolean',
          required: false,
          defaultValue: true,
          description: {
            zh: 'ç¼“å­˜OCRç»“æœä»¥é¿å…é‡å¤è°ƒç”¨',
            en: 'Cache OCR results to avoid duplicate calls'
          }
        },
        {
          id: 'batchSize',
          name: { zh: 'æ‰¹å¤„ç†å¤§å°', en: 'Batch Size' },
          type: 'number',
          required: false,
          defaultValue: 10,
          description: {
            zh: 'æ¯æ‰¹å¤„ç†çš„å›¾ç‰‡æ•°é‡',
            en: 'Number of images to process per batch'
          }
        }
      ],
      
      metadata: {
        author: 'Audit System',
        tags: ['preprocess', 'ocr', 'image', 'text-extraction', 'ai'],
        documentation: 'https://docs.audit-system.com/nodes/preprocess/ocr-extract',
        examples: [
          {
            title: 'æå–å‘ç¥¨æ–‡æœ¬',
            description: 'ä½¿ç”¨é˜¿é‡Œäº‘OCRæå–å‘ç¥¨å›¾ç‰‡æ–‡æœ¬',
            inputs: {
              images: {
                type: 'Records',
                data: [
                  { id: '001', image_path: '/path/to/invoice1.jpg' },
                  { id: '002', image_path: '/path/to/invoice2.jpg' }
                ]
              }
            },
            config: {
              provider: 'aliyun',
              language: 'zh',
              minConfidence: 0.8
            }
          }
        ]
      },
      
      capabilities: {
        cacheable: true,
        parallel: true,
        streaming: true,
        aiPowered: true
      }
    };
  }

  async execute(
    inputs: Record<string, AuditDataType>,
    config: Record<string, any>,
    context: NodeExecutionContext
  ): Promise<NodeExecutionResult> {
    const startTime = Date.now();
    
    try {
      const images = inputs.images as Records;
      const cfg: OCRConfig = {
        provider: config.provider || 'aliyun',
        language: config.language || 'auto',
        minConfidence: config.minConfidence ?? 0.5,
        enableCache: config.enableCache !== false,
        batchSize: config.batchSize || 10,
        timeout: config.timeout || 30000
      };
      
      context.logger?.info?.(`ğŸ” Processing ${images.rowCount} images with ${cfg.provider} OCR`);
      
      // æå–å›¾ç‰‡è·¯å¾„
      const imagePaths = this.extractImagePaths(images.data);
      
      // æ‰¹é‡å¤„ç†
      const results: Array<OCRResult> = [];
      const batches = this.createBatches(imagePaths, cfg.batchSize || 10);
      
      for (let i = 0; i < batches.length; i++) {
        const batch = batches[i];
        context.logger?.info?.(`  Processing batch ${i + 1}/${batches.length} (${batch.length} images)`);
        
        const batchResults = await this.processBatch(batch, cfg, context);
        results.push(...batchResults);
      }
      
      // è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ
      const filteredResults = results.filter(r => r.confidence >= (cfg.minConfidence || 0));
      
      context.logger?.info?.(`  Filtered: ${filteredResults.length}/${results.length} results (min confidence: ${cfg.minConfidence})`);
      
      // æ„é€ è¾“å‡º
      const texts: Records = {
        type: 'Records',
        schema: [
          { name: 'id', type: 'string', required: true, description: 'Image ID' },
          { name: 'text', type: 'string', required: true, description: 'Extracted Text' },
          { name: 'confidence', type: 'number', required: true, description: 'Confidence Score' },
          { name: 'line_count', type: 'number', required: false, description: 'Line Count' },
          { name: 'word_count', type: 'number', required: false, description: 'Word Count' }
        ],
        data: filteredResults.map((result, index) => ({
          id: images.data[index]?.id || `img_${index}`,
          text: result.text,
          confidence: result.confidence,
          line_count: result.lines.length,
          word_count: result.words.length
        })),
        metadata: this.createMetadata(context.nodeId, context.executionId, cfg.provider || 'unknown'),
        rowCount: filteredResults.length,
        columnCount: 5
      };
      
      const metadata: Records = {
        type: 'Records',
        schema: [
          { name: 'metric', type: 'string', required: true, description: 'Metric' },
          { name: 'value', type: 'number', required: true, description: 'Value' }
        ],
        data: [
          { metric: 'total_images', value: images.rowCount },
          { metric: 'successful', value: filteredResults.length },
          { metric: 'failed', value: images.rowCount - filteredResults.length },
          { metric: 'avg_confidence', value: this.calculateAvgConfidence(filteredResults) },
          { metric: 'total_lines', value: filteredResults.reduce((sum, r) => sum + r.lines.length, 0) }
        ],
        metadata: this.createMetadata(context.nodeId, context.executionId, 'metadata'),
        rowCount: 5,
        columnCount: 2
      };
      
      const duration = Date.now() - startTime;
      
      context.logger?.info?.(`âœ… OCR completed: ${filteredResults.length}/${images.rowCount} images (${duration}ms)`);
      
      return this.wrapSuccess(
        { texts, metadata },
        duration,
        context
      );
      
    } catch (error: any) {
      context.logger?.error?.('âŒ OCR extraction failed:', error);
      return this.wrapError('EXECUTION_ERROR', error.message, error.stack);
    }
  }

  // ============================================
  // ç§æœ‰æ–¹æ³•
  // ============================================

  private extractImagePaths(data: Array<Record<string, any>>): string[] {
    return data.map(row => {
      // å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
      return row.image_path || row.imagePath || row.path || row.file || row.url || '';
    }).filter(path => path !== '');
  }

  private createBatches<T>(items: T[], batchSize: number): T[][] {
    const batches: T[][] = [];
    for (let i = 0; i < items.length; i += batchSize) {
      batches.push(items.slice(i, i + batchSize));
    }
    return batches;
  }

  private async processBatch(
    imagePaths: string[],
    config: OCRConfig,
    context: NodeExecutionContext
  ): Promise<OCRResult[]> {
    const results: OCRResult[] = [];
    
    for (const imagePath of imagePaths) {
      try {
        // æ£€æŸ¥ç¼“å­˜
        if (config.enableCache && context.cache) {
          const cacheKey = `ocr:${config.provider}:${imagePath}`;
          const cached = await context.cache.get(cacheKey);
          if (cached) {
            results.push(cached as OCRResult);
            continue;
          }
        }
        
        // è°ƒç”¨OCRæœåŠ¡
        const result = await this.callOCRService(imagePath, config, context);
        results.push(result);
        
        // ä¿å­˜ç¼“å­˜
        if (config.enableCache && context.cache) {
          const cacheKey = `ocr:${config.provider}:${imagePath}`;
          await context.cache.set(cacheKey, result);
        }
        
      } catch (error: any) {
        context.logger?.warn?.(`âš ï¸  OCR failed for ${imagePath}: ${error.message}`);
        // è¿”å›ç©ºç»“æœ
        results.push({
          text: '',
          confidence: 0,
          lines: [],
          words: []
        });
      }
    }
    
    return results;
  }

  private async callOCRService(
    imagePath: string,
    config: OCRConfig,
    context: NodeExecutionContext
  ): Promise<OCRResult> {
    // å¦‚æœæœ‰AIæœåŠ¡ï¼Œä½¿ç”¨AIæœåŠ¡
    if (context.ai?.ocr) {
      const text = await context.ai.ocr(imagePath);
      
      // è§£æOCRå“åº”
      return this.parseOCRResponse(text, config.provider || 'aliyun');
    }
    
    // å¦åˆ™è¿”å›æ¨¡æ‹Ÿç»“æœï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    return this.mockOCRResult(imagePath);
  }

  private parseOCRResponse(response: any, provider: string): OCRResult {
    // æ ¹æ®ä¸åŒæœåŠ¡å•†è§£æå“åº”æ ¼å¼
    switch (provider) {
      case 'aliyun':
        return this.parseAliyunResponse(response);
      case 'baidu':
        return this.parseBaiduResponse(response);
      case 'tencent':
        return this.parseTencentResponse(response);
      default:
        return this.parseGenericResponse(response);
    }
  }

  private parseAliyunResponse(response: any): OCRResult {
    // é˜¿é‡Œäº‘OCRå“åº”æ ¼å¼
    const lines = response.prism_wordsInfo || [];
    const allText = lines.map((line: any) => line.word).join('\n');
    
    return {
      text: allText,
      confidence: lines.reduce((sum: number, line: any) => sum + (line.prob || 0), 0) / lines.length || 0,
      lines: lines.map((line: any) => ({
        text: line.word,
        confidence: line.prob || 0,
        boundingBox: line.pos
      })),
      words: allText.split(/\s+/).map((word: string) => ({
        text: word,
        confidence: 0.9  // é˜¿é‡Œäº‘ä¸æä¾›å•è¯çº§åˆ«ç½®ä¿¡åº¦
      }))
    };
  }

  private parseBaiduResponse(response: any): OCRResult {
    // ç™¾åº¦OCRå“åº”æ ¼å¼
    const words = response.words_result || [];
    const allText = words.map((w: any) => w.words).join('\n');
    
    return {
      text: allText,
      confidence: words.reduce((sum: number, w: any) => sum + (w.probability?.average || 0), 0) / words.length || 0,
      lines: words.map((w: any) => ({
        text: w.words,
        confidence: w.probability?.average || 0,
        boundingBox: [w.location.left, w.location.top, w.location.width, w.location.height]
      })),
      words: allText.split(/\s+/).map((word: string) => ({
        text: word,
        confidence: 0.9
      }))
    };
  }

  private parseTencentResponse(response: any): OCRResult {
    // è…¾è®¯äº‘OCRå“åº”æ ¼å¼
    const textDetections = response.TextDetections || [];
    const allText = textDetections.map((t: any) => t.DetectedText).join('\n');
    
    return {
      text: allText,
      confidence: textDetections.reduce((sum: number, t: any) => sum + (t.Confidence || 0), 0) / textDetections.length / 100 || 0,
      lines: textDetections.map((t: any) => ({
        text: t.DetectedText,
        confidence: (t.Confidence || 0) / 100,
        boundingBox: t.Polygon
      })),
      words: allText.split(/\s+/).map((word: string) => ({
        text: word,
        confidence: 0.9
      }))
    };
  }

  private parseGenericResponse(response: any): OCRResult {
    // é€šç”¨å“åº”æ ¼å¼ï¼ˆå‡è®¾è¿”å›çº¯æ–‡æœ¬ï¼‰
    const text = typeof response === 'string' ? response : JSON.stringify(response);
    
    return {
      text,
      confidence: 0.8,
      lines: text.split('\n').map(line => ({
        text: line,
        confidence: 0.8
      })),
      words: text.split(/\s+/).map(word => ({
        text: word,
        confidence: 0.8
      }))
    };
  }

  private mockOCRResult(imagePath: string): OCRResult {
    // å¼€å‘ç¯å¢ƒæ¨¡æ‹Ÿç»“æœ
    const mockText = `Mock OCR result for ${imagePath}\nLine 1: Sample text\nLine 2: Another line`;
    
    return {
      text: mockText,
      confidence: 0.95,
      lines: mockText.split('\n').map(line => ({
        text: line,
        confidence: 0.95
      })),
      words: mockText.split(/\s+/).map(word => ({
        text: word,
        confidence: 0.95
      }))
    };
  }

  private calculateAvgConfidence(results: OCRResult[]): number {
    if (results.length === 0) return 0;
    const sum = results.reduce((acc, r) => acc + r.confidence, 0);
    return sum / results.length;
  }
}
