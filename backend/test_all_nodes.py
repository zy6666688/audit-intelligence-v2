"""
å…¨é¢æµ‹è¯•æ‰€æœ‰èŠ‚ç‚¹çš„åŠŸèƒ½
éªŒè¯æ¯ä¸ªèŠ‚ç‚¹æ˜¯å¦èƒ½æ­£å¸¸æ‰§è¡Œå¹¶äº§ç”Ÿé¢„æœŸè¾“å‡º
"""
import sys
import os
import json
import traceback
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# åˆå§‹åŒ–èŠ‚ç‚¹æ³¨å†Œ
from app.core.registry import node_registry
import app.nodes.file_nodes
import app.nodes.clean_nodes
import app.nodes.audit_nodes
import app.nodes.viz_nodes
import app.nodes.script_nodes
import app.nodes.ai_nodes

node_registry.register_nodes_from_module("app.nodes.file_nodes")
node_registry.register_nodes_from_module("app.nodes.clean_nodes")
node_registry.register_nodes_from_module("app.nodes.audit_nodes")
node_registry.register_nodes_from_module("app.nodes.viz_nodes")
node_registry.register_nodes_from_module("app.nodes.script_nodes")
node_registry.register_nodes_from_module("app.nodes.ai_nodes")

# #region agent log - Test suite start
_log_path = r"d:\å®¡è®¡æ•°æ™ºæv2\.cursor\debug.log"
try:
    os.makedirs(os.path.dirname(_log_path), exist_ok=True)
    with open(_log_path, "a", encoding="utf-8") as _f:
        _f.write(json.dumps({
            "sessionId": "debug-session",
            "runId": "node-test-suite",
            "hypothesisId": "H1",
            "location": "test_all_nodes:start",
            "message": "node test suite started",
            "data": {
                "registered_nodes": list(node_registry.node_mappings.keys()),
                "node_count": len(node_registry.node_mappings)
            },
            "timestamp": int(__import__("time").time() * 1000)
        }, ensure_ascii=False) + "\n")
except:
    pass
# #endregion

# åˆ›å»ºæµ‹è¯•æ•°æ®
def create_test_dataframe():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„DataFrame"""
    return pd.DataFrame({
        "å‘ç¥¨å·ç ": ["INV-001", "INV-002", "INV-003", "INV-004"],
        "é‡‘é¢": [1000.0, 2000.0, None, 4000.0],
        "æ—¥æœŸ": ["2024-01-01", "2024-01-02", "2024-01-03", None],
        "ä¾›åº”å•†": ["ä¾›åº”å•†A", "ä¾›åº”å•†B", "ä¾›åº”å•†C", "ä¾›åº”å•†D"]
    })

def test_node(node_name, test_inputs, expected_output_types=None):
    """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹"""
    print(f"\n{'='*70}")
    print(f"Testing: {node_name}")
    print(f"{'='*70}")
    
    # #region agent log - Node test start
    try:
        with open(_log_path, "a", encoding="utf-8") as _f:
            _f.write(json.dumps({
                "sessionId": "debug-session",
                "runId": "node-test-suite",
                "hypothesisId": "H2",
                "location": f"test_all_nodes:test_node:{node_name}",
                "message": "node test started",
                "data": {
                    "node_name": node_name,
                    "test_inputs_keys": list(test_inputs.keys()),
                    "test_inputs_types": {k: type(v).__name__ for k, v in test_inputs.items()}
                },
                "timestamp": int(__import__("time").time() * 1000)
            }, ensure_ascii=False) + "\n")
    except:
        pass
    # #endregion
    
    try:
        # 1. è·å–èŠ‚ç‚¹ç±»
        node_class = node_registry.get_node_class(node_name)
        if not node_class:
            print(f"âŒ Node class not found: {node_name}")
            return False
        
        print(f"âœ… Node class found: {node_class.__name__}")
        
        # 2. å®ä¾‹åŒ–èŠ‚ç‚¹
        instance = node_class()
        print(f"âœ… Node instance created")
        
        # 3. è·å–æ‰§è¡Œå‡½æ•°
        func_name = getattr(node_class, "FUNCTION", "execute")
        func = getattr(instance, func_name)
        print(f"âœ… Execution function: {func_name}")
        
        # 4. æ‰§è¡ŒèŠ‚ç‚¹
        print(f"ğŸ”„ Executing with inputs: {list(test_inputs.keys())}")
        outputs = func(**test_inputs)
        
        # 5. éªŒè¯è¾“å‡º
        if isinstance(outputs, tuple):
            print(f"âœ… Output: tuple with {len(outputs)} items")
            for i, out in enumerate(outputs):
                if isinstance(out, pd.DataFrame):
                    print(f"   Output[{i}]: DataFrame {out.shape}")
                elif isinstance(out, (str, dict, list)):
                    print(f"   Output[{i}]: {type(out).__name__} (length: {len(out) if hasattr(out, '__len__') else 'N/A'})")
                else:
                    print(f"   Output[{i}]: {type(out).__name__} = {str(out)[:100]}")
        else:
            print(f"âœ… Output: {type(outputs).__name__}")
            if isinstance(outputs, pd.DataFrame):
                print(f"   Shape: {outputs.shape}")
        
        # 6. éªŒè¯è¾“å‡ºç±»å‹
        if expected_output_types:
            if isinstance(outputs, tuple):
                if len(outputs) != len(expected_output_types):
                    print(f"âš ï¸  Output count mismatch: expected {len(expected_output_types)}, got {len(outputs)}")
                else:
                    for i, (out, exp_type) in enumerate(zip(outputs, expected_output_types)):
                        if exp_type == "DATAFRAME" and not isinstance(out, pd.DataFrame):
                            print(f"âš ï¸  Output[{i}] type mismatch: expected DataFrame, got {type(out).__name__}")
                        elif exp_type == "STRING" and not isinstance(out, str):
                            print(f"âš ï¸  Output[{i}] type mismatch: expected str, got {type(out).__name__}")
                        elif exp_type == "DICT" and not isinstance(out, dict):
                            print(f"âš ï¸  Output[{i}] type mismatch: expected dict, got {type(out).__name__}")
        
        # #region agent log - Node test success
        try:
            output_info = {}
            if isinstance(outputs, tuple):
                output_info = {
                    "output_count": len(outputs),
                    "output_types": [type(o).__name__ for o in outputs]
                }
                if len(outputs) > 0 and isinstance(outputs[0], pd.DataFrame):
                    output_info["first_output_shape"] = list(outputs[0].shape)
            else:
                output_info = {
                    "output_type": type(outputs).__name__,
                    "is_dataframe": isinstance(outputs, pd.DataFrame)
                }
                if isinstance(outputs, pd.DataFrame):
                    output_info["shape"] = list(outputs.shape)
            
            with open(_log_path, "a", encoding="utf-8") as _f:
                _f.write(json.dumps({
                    "sessionId": "debug-session",
                    "runId": "node-test-suite",
                    "hypothesisId": "H2",
                    "location": f"test_all_nodes:test_node:{node_name}:success",
                    "message": "node test completed successfully",
                    "data": {
                        "node_name": node_name,
                        "success": True,
                        **output_info
                    },
                    "timestamp": int(__import__("time").time() * 1000)
                }, ensure_ascii=False) + "\n")
        except:
            pass
        # #endregion
        
        return True
        
    except Exception as e:
        error_msg = str(e)
        error_trace = traceback.format_exc()
        print(f"âŒ Error: {error_msg}")
        print(f"   Traceback:\n{error_trace[:500]}")
        
        # #region agent log - Node test error
        try:
            with open(_log_path, "a", encoding="utf-8") as _f:
                _f.write(json.dumps({
                    "sessionId": "debug-session",
                    "runId": "node-test-suite",
                    "hypothesisId": "H2",
                    "location": f"test_all_nodes:test_node:{node_name}:error",
                    "message": "node test failed",
                    "data": {
                        "node_name": node_name,
                        "error": error_msg,
                        "error_type": type(e).__name__,
                        "traceback": error_trace[:1000]
                    },
                    "timestamp": int(__import__("time").time() * 1000)
                }, ensure_ascii=False) + "\n")
        except:
            pass
        # #endregion
        
        return False

# æµ‹è¯•ç”¨ä¾‹å®šä¹‰
test_cases = []

# 1. ExcelLoader - éœ€è¦å®é™…æ–‡ä»¶
test_file = "input/sample_invoices.xlsx"
if os.path.exists(test_file):
    test_cases.append(("ExcelLoader", {
        "file_path": test_file
    }, ["DATAFRAME"]))

# 2. FileUploadNode - éœ€è¦å®é™…æ–‡ä»¶
if os.path.exists(test_file):
    test_cases.append(("FileUploadNode", {
        "file_path": test_file,
        "workflow_id": "test_workflow"
    }, ["STRING", "STRING", "DICT"]))

# 3. FileRecognitionNode - éœ€è¦å…ˆæœ‰ä¸Šä¼ çš„æ–‡ä»¶
# è·³è¿‡ï¼Œéœ€è¦å…ˆè¿è¡ŒFileUploadNode

# 4. ColumnMapperNode - éœ€è¦DataFrame
test_df = create_test_dataframe()
test_cases.append(("ColumnMapperNode", {
    "dataframe": test_df,
    "mapping_json": '{"å‘ç¥¨å·ç ":"invoice_no","é‡‘é¢":"amount","æ—¥æœŸ":"date"}',
    "keep_other_columns": True,
    "strict_mode": False
}, ["DATAFRAME", "STRING"]))

# 5. NullValueCleanerNode - éœ€è¦DataFrame
test_cases.append(("NullValueCleanerNode", {
    "dataframe": test_df,
    "target_columns": "amount,æ—¥æœŸ",
    "strategy": "drop_rows"
}, ["DATAFRAME", "STRING"]))

# 6. ExcelColumnValidator - éœ€è¦DataFrame
test_cases.append(("ExcelColumnValidator", {
    "dataframe": test_df,
    "column_name": "é‡‘é¢",
    "min_value": 0,
    "max_value": 5000,
    "include_bounds": True
}, ["DATAFRAME", "STRING"]))

# 7. AuditCheckNode - åªéœ€è¦amountå’Œthreshold
test_cases.append(("AuditCheckNode", {
    "amount": 2000.0,
    "threshold": 1500.0
}, ["BOOLEAN", "STRING"]))

# 8. QuickPlotNode - éœ€è¦DataFrame
test_cases.append(("QuickPlotNode", {
    "dataframe": test_df,
    "chart_type": "bar",
    "x_column": "å‘ç¥¨å·ç ",
    "y_column": "é‡‘é¢",
    "title": "æµ‹è¯•å›¾è¡¨"
}, ["STRING"]))

# 9. DataFrameToTableNode - éœ€è¦DataFrame
test_cases.append(("DataFrameToTableNode", {
    "dataframe": test_df,
    "max_rows": 10
}, ["STRING"]))

# 10. PythonScriptNode - éœ€è¦DataFrameå’Œè„šæœ¬
test_cases.append(("PythonScriptNode", {
    "dataframe": test_df,
    "script": "result = dataframe.copy()\nresult['new_col'] = result['é‡‘é¢'] * 2\noutput = result"
}, ["DATAFRAME", "STRING"]))

# 11. CommonMetricsNode - éœ€è¦DataFrame
test_cases.append(("CommonMetricsNode", {
    "dataframe": test_df
}, ["DICT"]))

# 12. SceneMetricsNode - éœ€è¦DataFrameå’Œbusiness_scene
test_cases.append(("SceneMetricsNode", {
    "dataframe": test_df,
    "business_scene": "invoice_audit"
}, ["DICT"]))

# 13. RuleCalculationNode - éœ€è¦DataFrameå’Œmetrics
test_cases.append(("RuleCalculationNode", {
    "dataframe": test_df,
    "metrics": {"amount_mean": 2000.0, "amount_std": 1000.0}
}, ["DATAFRAME", "INT"]))

# 14. TextUnderstandingAI - éœ€è¦æ–‡æœ¬
test_cases.append(("TextUnderstandingAI", {
    "text_data": "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯•AIæ–‡æœ¬ç†è§£åŠŸèƒ½ã€‚",
    "task_type": "classify"
}, ["LIST", "LIST", "DICT"]))

# 15. ImageRecognitionAI - éœ€è¦å›¾ç‰‡è·¯å¾„ï¼ˆè·³è¿‡ï¼Œéœ€è¦å®é™…å›¾ç‰‡ï¼‰
# test_cases.append(("ImageRecognitionAI", {...}))

# 16. AnalysisReasoningAI - éœ€è¦DataFrameå’ŒæŒ‡æ ‡
test_risk_df = pd.DataFrame([{"risk_level": "HIGH", "amount": 2000}])
test_cases.append(("AnalysisReasoningAI", {
    "risk_items": test_risk_df,
    "metrics": {"total_amount": 2000, "threshold": 1500}
}, ["STRING", "DICT"]))

# 17. HumanReviewNode - éœ€è¦DataFrameå’Œè¯„ä¼°
test_cases.append(("HumanReviewNode", {
    "risk_items": test_risk_df,
    "risk_assessment": {"risk_level": "HIGH", "risk_score": 75}
}, ["DICT"]))

# 18. ResultGenerationNode - éœ€è¦DataFrameå’Œè¯„ä¼°
test_cases.append(("ResultGenerationNode", {
    "risk_items": test_risk_df,
    "risk_assessment": {"risk_level": "HIGH", "risk_score": 75}
}, ["STRING"]))

# 19. ExportReportNode - éœ€è¦å®¡è®¡ç»“æœå’Œæ ¼å¼
test_cases.append(("ExportReportNode", {
    "audit_result": {"summary": {"total_items": 1}, "findings": []},
    "export_format": "json"
}, ["STRING", "STRING"]))

if __name__ == "__main__":
    print("="*70)
    print("Node Functionality Test Suite")
    print("="*70)
    print(f"Total test cases: {len(test_cases)}")
    print(f"Registered nodes: {len(node_registry.node_mappings)}")
    
    results = {}
    passed = 0
    failed = 0
    
    for node_name, inputs, expected_types in test_cases:
        success = test_node(node_name, inputs, expected_types)
        results[node_name] = success
        if success:
            passed += 1
        else:
            failed += 1
    
    print("\n" + "="*70)
    print("Test Summary")
    print("="*70)
    print(f"Total: {len(test_cases)}")
    print(f"âœ… Passed: {passed}")
    print(f"âŒ Failed: {failed}")
    print("\nFailed nodes:")
    for node_name, success in results.items():
        if not success:
            print(f"  - {node_name}")
    
    # #region agent log - Test suite end
    try:
        with open(_log_path, "a", encoding="utf-8") as _f:
            _f.write(json.dumps({
                "sessionId": "debug-session",
                "runId": "node-test-suite",
                "hypothesisId": "H1",
                "location": "test_all_nodes:end",
                "message": "node test suite completed",
                "data": {
                    "total": len(test_cases),
                    "passed": passed,
                    "failed": failed,
                    "results": results
                },
                "timestamp": int(__import__("time").time() * 1000)
            }, ensure_ascii=False) + "\n")
    except:
        pass
    # #endregion

